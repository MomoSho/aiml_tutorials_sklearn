{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to Scikit-Learn and Pandas\n",
    "Artifical Intelligence and Machine Learning Symposium at OU\n",
    "Univeristy of Oklahoma Memorial Union Ballroom\n",
    "September 25, 2019 Author: Keerti Banweer keerti.banweer@ou.edu\n",
    "\n",
    "## Overview: Dimensionality reduction and Clustering (Breast Cancer dataset)\n",
    "Below are the topics that will be covered in this section:\n",
    "\n",
    "1. Load the dataset using sklearn.datasets\n",
    "2. Describe the dataset using DESCR\n",
    "3. Check for missing values using numpy functions isnan() and any()\n",
    "4. Scale the data using sklearn scaler (we will be using min max scaler)\n",
    "5. Dimensionality reduction using PCA and tSNE functions in Sklearn\n",
    "6. build the models using sklearn packages: Kmeans\n",
    "7. Evaluate the predictions, check accuracy\n",
    "8. visualizing the clusters with different graphs \n",
    "   compare different models using cross validation (sklearn.model_selection.cross_validate )\n",
    "\n",
    "### General References\n",
    "* [Sci-kit Learn API](https://scikit-learn.org/stable/modules/classes.html)\n",
    "\n",
    "Clustering is a technique of identifying similar instances and assigning them to clusters \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Index of sklearn datasets https://scikit-learn.org/stable/datasets/index.html #datasets\n",
    "# https://scikit-learn.org/stable/modules/classes.html\n",
    "# module-sklearn.datasets\n",
    "\n",
    "\"\"\"\n",
    "This section will import all the required packages for this tutorial\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer, load_iris\n",
    "from sklearn import cluster, datasets\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools \n",
    "import time\n",
    "\n",
    "from matplotlib import rcParams, pyplot as plt\n",
    "# Though the following import is not directly being used, it is required\n",
    "# for 3D projection to work\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib.ticker import NullFormatter\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from sklearn.metrics.cluster import contingency_matrix \n",
    "from sklearn.metrics.pairwise import paired_euclidean_distances\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "from sklearn.cluster import KMeans, AffinityPropagation\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "rcParams['figure.figsize'] = (8, 8)\n",
    "\n",
    "globalStart = time.time()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "In this section, we will understand and visualize structure of breast cancer dataset from sklearn.\n",
    "feature_names will lists all the names of the different attributes\n",
    "target_names are the names of the classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n1. We will load breast cancer dataset\\n2. Using the function keys(), we will display all the keys of the dataset\\n3. DESCR will describe the dataset. It includes the list of attributes and their meaning. \\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "1. We will load breast cancer dataset\n",
    "2. Using the function keys(), we will display all the keys of the dataset\n",
    "3. DESCR will describe the dataset. It includes the list of attributes and their meaning. \n",
    "\"\"\"\n",
    "\n",
    "#loading breast cancer dataset \n",
    "\n",
    "\n",
    "## Display the keys\n",
    "\n",
    "\n",
    "## Describe the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nStore the data in variable X and using pandas, we convert it into a dataframe\\nFeature names and target names are available under keys: feature_names and target_names respectively\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Store the data in variable X and using pandas, we convert it into a dataframe\n",
    "Feature names and target names are available under keys: feature_names and target_names respectively\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' \\nStore the number of samples and the number of features, by\\naccessing the values from the shape of X\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" \n",
    "Store the number of samples and the number of features, by\n",
    "accessing the values from the shape of X\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Breast cancer dataset loaded in the form of dictionary\n",
    "## changing it to pandas dataframe for more features\n",
    "\n",
    "# data = np.c_[bc_dataset.data, bc_dataset.target]\n",
    "# columns = np.append(bc_dataset.feature_names, [\"target\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data clean up\n",
    "\n",
    "Check for any missing values using isna() and any(). \n",
    "We can use functions like head() and tail() to view top 5 and bottom 5 rows of the dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nUsing head() fucntion, we can check top 5 rows of the dataframe\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Using head() fucntion, we can check top 5 rows of the dataframe\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nUsing tail() function we can check last 5 rows\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Using tail() function we can check last 5 rows\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check for missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' \\nDetermine whether any data are NaN. Use isna() and\\nany() to obtain a summary of which features have at \\nleast one missing value\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" \n",
    "Determine whether any data are NaN. Use isna() and\n",
    "any() to obtain a summary of which features have at \n",
    "least one missing value\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nList of attributes\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "List of attributes\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Histogram of the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nHISTOGRAMS OF THE PREDICTOR FEATURES \\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "HISTOGRAMS OF THE PREDICTOR FEATURES \n",
    "\"\"\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalizing and Scaling the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nUse Min-Max scaler from sklearn\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Use Min-Max scaler from sklearn\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nDisplay the scaled data using histograms\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Display the scaled data using histograms\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA for Dimensionality Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nPrincipal Component Analysis (PCA) is one of the popular dimensionality reduction algorithm\\nVisualize using bar plot\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Principal Component Analysis (PCA) is one of the popular dimensionality reduction algorithm\n",
    "Visualize using bar plot\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nDisplay top five rows of PCA\\n'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Display top five rows of PCA\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nUsing seaborn to display the PCS distribution\\n'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Using seaborn to display the PCS distribution\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 3D version of the same plot\n",
    "\n",
    "# num_classes = len(np.unique(colors))\n",
    "# palette = np.array(sns.color_palette(\"hls\", num_classes))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tSNE for dimensionality reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Also use tSNE for dimensionality reduction\n",
    "##T-Distributed Stochastic Neighbouring Entities (t-SNE)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## In this section we will use seaborn to visualize\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nTrain a KMeans cluster for breast cancer dataset\\nWe need to specify the number of clusters that algorithm will find\\nIn the next section, we will compare the clusters with n_clusters 2, 4, 8\\n'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Train a KMeans cluster for breast cancer dataset\n",
    "We need to specify the number of clusters that algorithm will find\n",
    "In the next section, we will compare the clusters with n_clusters 2, 4, 8\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nCentroid and labels for clustering\\n'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Centroid and labels for clustering\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Add 3rd dimension to figure\n",
    "\n",
    "\n",
    "# Plot all the features and assign color based on cluster identity label\n",
    "\n",
    "\n",
    "# Plot centroids, though you can't really see them.\n",
    "\n",
    "\n",
    "#Set labels on figure and show 3D scatter plot to visualize data and clusters.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CLUSTERING DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RETREIVING CLUSTER EXAMPLE INDICIES\n",
    "def get_examples_in_cluster_c(estimator, X, c):\n",
    "    nclusters = estimator.cluster_centers_.shape[0]\n",
    "    inds = np.where(estimator.labels_ == c)[0]\n",
    "    return inds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_bc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-48ac387aa79c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# https://scikit-learn.org/stable/auto_examples/cluster/plot_cluster_iris.html\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mfeatures_diff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_bc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mselected_features\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mkmeans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKMeans\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_clusters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mkmeans\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures_diff\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data_bc' is not defined"
     ]
    }
   ],
   "source": [
    "# https://scikit-learn.org/stable/auto_examples/cluster/plot_cluster_iris.html\n",
    "features_diff = np.array(data_bc[selected_features])\n",
    "kmeans = KMeans(n_clusters=2)\n",
    "kmeans.fit(features_diff)\n",
    "\n",
    "# Observing different Cluster counts\n",
    "'''\n",
    "TUTORIAL NOTES: Just have them play with different cluster sizes in the constructors\n",
    "'''\n",
    "estimators = [('2_clusters1', KMeans(n_clusters=2)),\n",
    "              ('4_clusters2', KMeans(n_clusters=4)),\n",
    "              ('8_clusters', KMeans(n_clusters=8))]\n",
    "titles = ['2 Clusters','4 Clusters','8 Clusters']\n",
    "\n",
    "plt.figure(1)\n",
    "for i, (name, est) in enumerate(estimators):\n",
    "    (fig, sub) = plt.subplots(2, 2, num=i+1)\n",
    "    xx = int(i > 1)\n",
    "    yy = i % 2\n",
    "    ax = Axes3D(fig, rect=[0, 0, .95, 1], elev=48, azim=134)\n",
    "    est.fit(features_diff)\n",
    "    labels = est.labels_\n",
    "\n",
    "    ax.scatter(features_diff[:, 0], features_diff[:, 1], features_diff[:, 2], c=labels.astype(np.float), edgecolor='k')\n",
    "\n",
    "    ax.w_xaxis.set_ticklabels([])\n",
    "    ax.w_yaxis.set_ticklabels([])\n",
    "    ax.w_zaxis.set_ticklabels([])\n",
    "    ax.set_xlabel('Radius Mean')\n",
    "    ax.set_ylabel('Concavity Mean')\n",
    "    ax.set_zlabel('Symmetry length')\n",
    "    ax.set_title(titles[i])\n",
    "    ax.dist = 12\n",
    "    plt.show()\n",
    "\n",
    "# Plot the ground truth\n",
    "fig = plt.figure(4)\n",
    "ax = Axes3D(fig, rect=[0, 0, .95, 1], elev=48, azim=134)\n",
    "for label, name in enumerate(targ_names):\n",
    "    ax.text3D(features[y == label, 0].mean(),\n",
    "              features[y == label, 1].mean(),\n",
    "              features[y == label, 2].mean() + 2, name,\n",
    "              horizontalalignment='center',\n",
    "              bbox=dict(alpha=.2, edgecolor='w', facecolor='w'))\n",
    "# Reorder the labels to have colors matching the cluster results\n",
    "y = np.choose(y, [0, 1, 2]).astype(np.float)\n",
    "ax.scatter(features[:, 0], features[:, 1], features[:, 2], c=y, edgecolor='k')\n",
    "ax.w_xaxis.set_ticklabels([])\n",
    "ax.w_yaxis.set_ticklabels([])\n",
    "ax.w_zaxis.set_ticklabels([])\n",
    "ax.set_xlabel('Radius Mean')\n",
    "ax.set_ylabel('Concavity Mean')\n",
    "ax.set_zlabel('Symmetry length')\n",
    "ax.set_title('Ground Truth')\n",
    "ax.dist = 12\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering using AffinityPropagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_affinity = AffinityPropagation(damping=0.5, max_iter=300, affinity='euclidean', verbose=False)\n",
    "data_affinity = np.array(features_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display affinity propagation clustering method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analysing, visualizing dataset\n",
    "\n",
    "def plot_confusion_matrix(cm, classes, normalize=False, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()\n",
    "    #plt.savefig('confusion_mtx', bbox_inches=\"tight\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
